(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{209:function(t,a,s){"use strict";s.r(a);var e=s(0),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"api-reference"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#api-reference","aria-hidden":"true"}},[t._v("#")]),t._v(" API Reference")]),t._v(" "),s("p",[t._v("Main module.")]),t._v(" "),s("h2",{attrs:{id:"max-ascii"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#max-ascii","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("MAX_ASCII")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("MAX_ASCII "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("126")]),t._v("\n")])])]),s("h2",{attrs:{id:"dna"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#dna","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("dna()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("dna")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_gaps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" uppercase_only"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Optional"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Generates DNA sequences.")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous bases are permitted.")]),t._v(" "),s("li",[s("code",[t._v("allow_gaps")]),t._v(": Whether a "),s("code",[t._v("-")]),t._v(" may be in the DNA sequence.")]),t._v(" "),s("li",[s("code",[t._v("uppercase_only")]),t._v(": Whether to use only uppercase characters.")]),t._v(" "),s("li",[s("code",[t._v("min_size")]),t._v(": The shortest DNA sequence to generate.")]),t._v(" "),s("li",[s("code",[t._v("max_size")]),t._v(": The longest DNA sequence to generate.")])]),t._v(" "),s("h2",{attrs:{id:"rna"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rna","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("rna()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rna")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_gaps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_lowercase"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Optional"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Generates RNA sequences.")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous bases are permitted.")]),t._v(" "),s("li",[s("code",[t._v("allow_gaps")]),t._v(": Whether a "),s("code",[t._v("-")]),t._v(" may be in the RNA sequence.")]),t._v(" "),s("li",[s("code",[t._v("allow_lowercase")]),t._v(": Whether lowercase characters should be used.")]),t._v(" "),s("li",[s("code",[t._v("min_size")]),t._v(": The shortest RNA sequence to generate")]),t._v(" "),s("li",[s("code",[t._v("max_size")]),t._v(": The longest RNA sequence to generate")])]),t._v(" "),s("h2",{attrs:{id:"protein"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#protein","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("protein()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("protein")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_extended"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" single_letter_protein"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" uppercase_only"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Optional"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Generates protein sequences.")]),t._v(" "),s("div",{staticClass:"tip custom-block"},[s("p",{staticClass:"custom-block-title"},[t._v("Tip")]),t._v(" "),s("p",[t._v("By default, only canonical amino acids are used.")])]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("allow_extended")]),t._v(": Whether the extended amino acid alphabet should be used.")]),t._v(" "),s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous amino acids are permitted.")]),t._v(" "),s("li",[s("code",[t._v("single_letter_protein")]),t._v(": Whether 1-letter or 3-letter abbreviations of proteins should be used.")]),t._v(" "),s("li",[s("code",[t._v("uppercase_only")]),t._v(": Whether to restrict the protein sequence to uppercase characters.")]),t._v(" "),s("li",[s("code",[t._v("min_size")]),t._v(": The shortest protein sequence to generate.")]),t._v(" "),s("li",[s("code",[t._v("max_size")]),t._v(": The longest protein sequence to generate.")])]),t._v(" "),s("h2",{attrs:{id:"start-codon"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#start-codon","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("start_codon()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("start_codon")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Strategy to generate "),s("a",{attrs:{href:"https://en.wikipedia.org/wiki/Start_codon",target:"_blank",rel:"noopener noreferrer"}},[t._v("start codons"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous bases are permitted.")])]),t._v(" "),s("h2",{attrs:{id:"stop-codon"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#stop-codon","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("stop_codon()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("stop_codon")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Strategy to generate "),s("a",{attrs:{href:"https://en.wikipedia.org/wiki/Stop_codon",target:"_blank",rel:"noopener noreferrer"}},[t._v("stop codons"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous bases are permitted.")])]),t._v(" "),s("h2",{attrs:{id:"cds"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#cds","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("cds()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("cds")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" include_start_codon"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" include_stop_codon"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_internal_stop_codons"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" uppercase_only"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Generates "),s("a",{attrs:{href:"https://en.wikipedia.org/wiki/Coding_region",target:"_blank",rel:"noopener noreferrer"}},[t._v("coding DNA sequences"),s("OutboundLink")],1),t._v(" (CDSs).")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("include_start_codon")]),t._v(": Whether to include a "),s("a",{attrs:{href:"#start_codon"}},[t._v("start codon")]),t._v(" at the beginning.")]),t._v(" "),s("li",[s("code",[t._v("include_stop_codon")]),t._v(": Whether to include a "),s("a",{attrs:{href:"#stop_codon"}},[t._v("stop codon")]),t._v(" at the end.")]),t._v(" "),s("li",[s("code",[t._v("allow_internal_stop_codons")]),t._v(": Whether stop codons may occur at any place other than the end.")]),t._v(" "),s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous bases are permitted.")]),t._v(" "),s("li",[s("code",[t._v("uppercase_only")]),t._v(": Whether to use only uppercase characters.")]),t._v(" "),s("li",[s("code",[t._v("min_size")]),t._v(": The shortest CDS to generate in base pairs.")]),t._v(" "),s("li",[s("code",[t._v("max_size")]),t._v(": The longest CDS to generate in base pairs.")])]),t._v(" "),s("h2",{attrs:{id:"fasta"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fasta","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("fasta()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fasta")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" comment_source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" SearchStrategy "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sequence_source"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" SearchStrategy "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" wrap_length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Optional"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_windows_line_endings"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Generates FASTA sequences.")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("comment_source")]),t._v(": The source of the comments. Defaults to "),s("code",[t._v("text(alphabet=characters(min_codepoint=32, max_codepoint=126))")]),t._v(")")]),t._v(" "),s("li",[s("code",[t._v("sequence_source")]),t._v(": The source of the sequence. Defaults to "),s("a",{attrs:{href:"#dna"}},[s("code",[t._v("dna")])]),t._v(".")]),t._v(" "),s("li",[s("code",[t._v("wrap_length")]),t._v(": The width to wrap the sequence on. If "),s("code",[t._v("None")]),t._v(", mixed sizes are used.")]),t._v(" "),s("li",[s("code",[t._v("allow_windows_line_endings")]),t._v(": Whether to allow "),s("code",[t._v("\\\\r\\\\n")]),t._v(" in the linebreaks.")])]),t._v(" "),s("h2",{attrs:{id:"kmers"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#kmers","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("kmers()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("kmers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seq"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Generates k-mers (short sliding window substrings) from a given sequence")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("seq")]),t._v(": The sequence to be used for generating k-mers")]),t._v(" "),s("li",[s("code",[t._v("k")]),t._v(": Size of the substrings to be generated")])]),t._v(" "),s("h2",{attrs:{id:"sequence-id"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sequence-id","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("sequence_id()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence_id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" blacklist_characters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Sequence"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('">@"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Generates a sequence ID.")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("blacklist_characters")]),t._v(": Characters to not include in the sequence ID.")]),t._v(" "),s("li",[s("code",[t._v("max_size")]),t._v(": Maximum length of the sequence ID.")])]),t._v(" "),s("h2",{attrs:{id:"fastq-quality"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fastq-quality","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("fastq_quality()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fastq_quality")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("62")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" offset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Generates the quality string for the FASTQ format")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("size")]),t._v(": Size of the quality string to be generated")]),t._v(" "),s("li",[s("code",[t._v("min_score")]),t._v(": Lowest quality (PHRED) score to use.")]),t._v(" "),s("li",[s("code",[t._v("max_score")]),t._v(": Highest quality (PHRED) score to use.")]),t._v(" "),s("li",[s("code",[t._v("offset")]),t._v(": ASCII encoding offset.")])]),t._v(" "),s("p",[t._v("Note:\nSee "),s("a",{attrs:{href:"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2847217/",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2847217/"),s("OutboundLink")],1),t._v(" for more details on\nthe quality score encoding.")]),t._v(" "),s("h2",{attrs:{id:"fastq"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fastq","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("fastq()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fastq")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("62")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" offset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" add_comment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" additional_description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bool")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Generate strings representing sequences in FASTQ format.")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("size")]),t._v(": Size of the sequence and quality string.")]),t._v(" "),s("li",[s("code",[t._v("min_score")]),t._v(": Lowest quality (PHRED) score to use.")]),t._v(" "),s("li",[s("code",[t._v("max_score")]),t._v(": Highest quality (PHRED) score to use.")]),t._v(" "),s("li",[s("code",[t._v("offset")]),t._v(": ASCII encoding offset for quality string.")]),t._v(" "),s("li",[s("code",[t._v("add_comment")]),t._v(": Add a comment string after the sequence ID, separated by a space.")]),t._v(" "),s("li",[s("code",[t._v("additional_description")]),t._v(": Add sequence ID and comment after "),s("code",[t._v("+")]),t._v(" on third line.")])]),t._v(" "),s("p",[t._v("Note:\nSee "),s("a",{attrs:{href:"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2847217/",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2847217/"),s("OutboundLink")],1),t._v(" for more details on\nthe FASTQ format (and its quality score encoding).")])])}),[],!1,null,null,null);a.default=n.exports}}]);