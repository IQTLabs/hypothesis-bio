(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{212:function(t,a,s){"use strict";s.r(a);var e=s(0),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"sequences"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sequences","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("sequences")])]),t._v(" "),s("h2",{attrs:{id:"dna"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#dna","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("dna()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("dna")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_gaps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" uppercase_only"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Optional"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Generates DNA sequences.")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous bases are permitted.")]),t._v(" "),s("li",[s("code",[t._v("allow_gaps")]),t._v(": Whether a "),s("code",[t._v("-")]),t._v(" may be in the DNA sequence.")]),t._v(" "),s("li",[s("code",[t._v("uppercase_only")]),t._v(": Whether to use only uppercase characters.")]),t._v(" "),s("li",[s("code",[t._v("min_size")]),t._v(": The shortest DNA sequence to generate.")]),t._v(" "),s("li",[s("code",[t._v("max_size")]),t._v(": The longest DNA sequence to generate.")])]),t._v(" "),s("h2",{attrs:{id:"rna"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rna","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("rna()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rna")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_gaps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_lowercase"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Optional"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Generates RNA sequences.")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous bases are permitted.")]),t._v(" "),s("li",[s("code",[t._v("allow_gaps")]),t._v(": Whether a "),s("code",[t._v("-")]),t._v(" may be in the RNA sequence.")]),t._v(" "),s("li",[s("code",[t._v("allow_lowercase")]),t._v(": Whether lowercase characters should be used.")]),t._v(" "),s("li",[s("code",[t._v("min_size")]),t._v(": The shortest RNA sequence to generate")]),t._v(" "),s("li",[s("code",[t._v("max_size")]),t._v(": The longest RNA sequence to generate")])]),t._v(" "),s("h2",{attrs:{id:"protein"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#protein","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("protein()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("protein")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_extended"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" single_letter_protein"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" uppercase_only"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Optional"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Generates protein sequences.")]),t._v(" "),s("div",{staticClass:"tip custom-block"},[s("p",{staticClass:"custom-block-title"},[t._v("Tip")]),t._v(" "),s("p",[t._v("By default, only canonical amino acids are used.")])]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("allow_extended")]),t._v(": Whether the extended amino acid alphabet should be used.")]),t._v(" "),s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous amino acids are permitted.")]),t._v(" "),s("li",[s("code",[t._v("single_letter_protein")]),t._v(": Whether 1-letter or 3-letter abbreviations of proteins should be used.")]),t._v(" "),s("li",[s("code",[t._v("uppercase_only")]),t._v(": Whether to restrict the protein sequence to uppercase characters.")]),t._v(" "),s("li",[s("code",[t._v("min_size")]),t._v(": The shortest protein sequence to generate.")]),t._v(" "),s("li",[s("code",[t._v("max_size")]),t._v(": The longest protein sequence to generate.")])]),t._v(" "),s("h2",{attrs:{id:"start-codon"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#start-codon","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("start_codon()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("start_codon")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Strategy to generate "),s("a",{attrs:{href:"https://en.wikipedia.org/wiki/Start_codon",target:"_blank",rel:"noopener noreferrer"}},[t._v("start codons"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous bases are permitted.")])]),t._v(" "),s("h2",{attrs:{id:"stop-codon"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#stop-codon","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("stop_codon()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("stop_codon")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Strategy to generate "),s("a",{attrs:{href:"https://en.wikipedia.org/wiki/Stop_codon",target:"_blank",rel:"noopener noreferrer"}},[t._v("stop codons"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous bases are permitted.")])]),t._v(" "),s("h2",{attrs:{id:"cds"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#cds","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("cds()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("cds")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" include_start_codon"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" include_stop_codon"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_internal_stop_codons"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_ambiguous"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" uppercase_only"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Generates "),s("a",{attrs:{href:"https://en.wikipedia.org/wiki/Coding_region",target:"_blank",rel:"noopener noreferrer"}},[t._v("coding DNA sequences"),s("OutboundLink")],1),t._v(" (CDSs).")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("include_start_codon")]),t._v(": Whether to include a "),s("a",{attrs:{href:"#start_codon"}},[t._v("start codon")]),t._v(" at the beginning.")]),t._v(" "),s("li",[s("code",[t._v("include_stop_codon")]),t._v(": Whether to include a "),s("a",{attrs:{href:"#stop_codon"}},[t._v("stop codon")]),t._v(" at the end.")]),t._v(" "),s("li",[s("code",[t._v("allow_internal_stop_codons")]),t._v(": Whether stop codons may occur at any place other than the end.")]),t._v(" "),s("li",[s("code",[t._v("allow_ambiguous")]),t._v(": Whether ambiguous bases are permitted.")]),t._v(" "),s("li",[s("code",[t._v("uppercase_only")]),t._v(": Whether to use only uppercase characters.")]),t._v(" "),s("li",[s("code",[t._v("min_size")]),t._v(": The shortest CDS to generate in base pairs.")]),t._v(" "),s("li",[s("code",[t._v("max_size")]),t._v(": The longest CDS to generate in base pairs.")])]),t._v(" "),s("h2",{attrs:{id:"kmers"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#kmers","aria-hidden":"true"}},[t._v("#")]),t._v(" "),s("code",[t._v("kmers()")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@composite")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("kmers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("draw"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seq"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v("\n")])])]),s("p",[t._v("Generates k-mers (short sliding window substrings) from a given sequence")]),t._v(" "),s("p",[t._v("Arguments:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("seq")]),t._v(": The sequence to be used for generating k-mers")]),t._v(" "),s("li",[s("code",[t._v("k")]),t._v(": Size of the substrings to be generated")])])])}),[],!1,null,null,null);a.default=n.exports}}]);